# 9. Virtual Memory

물리적인 메모리의 주소변환은 운영체제가 관여하지 않는다. 하지만 가상 메모리는 전적으로 운영체제가 관여한다.

실제로 대부분 페이징 기법을 사용하고 있어서, 이 장은 페이징기법을 사용하는 바탕으로 이야기할 것. 

## Demand Paging 요구 페이징

```
실제로 필요할 때 (요청이 있을 때) 그 페이지를 메모리에 올리는 것
```

- I/O 양의 감소 

  - 필요한 것만 올리기 때문에

- Memory 사용량 감소

- 빠른 응답시간

- 더 많은 사용자 수용 

  

**Lazy swapper(pager)**

한번도 접근되지 않는 페이지는 물리메모리에 절대 적재되지 않을 것



### Valid & Invalid Bits

현재 메모리에 없다는 것을 알기위해 Page Table에 valid/invalid bit를 사용함 

| --      | 8장 메모리관리                                            | 9장 가상메모리                                               |
| ------- | --------------------------------------------------------- | ------------------------------------------------------------ |
| invalid | Illegal의미 <br />memory protection, 자기 영역이 아닌경우 | 1. 페이지가 물리적 메모리에 없는 경우 (Not in Memory) <br />2. Illegal 사용되지 않는 주소영역 (아래 그림에서 G,H) |

- 처음에는 모든 Page entry가 invalid
- **Page fault**: 요청한 페이지가 메모리에 없는 현상



![스크린샷 2022-03-28 오전 1.44.58](./img/스크린샷%202022-03-28%20오전%201.44.58.png)  





### Page fault

**page fault trap**

invalid page를 접근하면 MMU가 trap을 발생시켜 kernel mode로 들어가서 page fault handler가 invoke된다.   

Disk에 I/O를 해야하기 때문에 CPU 제어권이 운영체제에게 넘어감 

```
# page fault 처리 순서
1. check
	- invalid reference (illegal) => abort
	- 정상 메모리인데 Just not in memory 인 경우라면 2번 수행 
2. 비어있는 frame 확보 (frame table에서)
3. paging in (Swap) -- (I/O 작업 일어남 )
  - 그동안 프로세스의 상태가 wating이라서 오래걸림
4. page table update
  - validation bit 'v'로 바꿔줌
5. ready queue에 process 추가 
6. page fault 발생한 시점부터 재 수행 
```

![스크린샷 2022-03-28 오전 1.51.49](./img/스크린샷%202022-03-28%20오전%201.51.49.png)

```
1. page table lookup
2. empty frame 확보 
3. swapping in
4. update
5. valid
6. 재수행 
```



### Pure paging

- 메모리에 페이지가 하나도 없는 상태로 시작 
- page fault발생 
- **참조의 지역성(Locality of reference)** 
  - 보통 특정 page만 집중적으로 참조하므로 처음엔 page fault 좀 발생하지만 꽤 성능 좋음 

### Performance of Demand Paging

- page fault rate
  - p = 0 :  page fault 일어나지 않음 *-- 가급적 0에 가깝도록 해야함* 
  - p = 1 : 매번 발생
- EAT ( Effective Access Time )
  - (1-p) x memoy access + p (overhead)
  - page fault발생하면 성능저하가 매우 크므로 page fault를 줄이기위해 swap space을 잘 관리하는 것이 중요하다. 



## Page replacement 페이지 교체

```
목표 : Page fault 횟수 최소화 
<핵심> 비어있는 frame이 없을 때 누구를 쫓아낼 것인가?
```



**Basic replacement 전략**

![스크린샷 2022-03-28 오전 2.00.57](./img/스크린샷%202022-03-28%20오전%202.00.57.png)

- 디스크에서 필요한 page 위치 알아냄
- 빈 frame 찾음
  - 있다면 사용
  - 없다면 victim frame 선정하기위한 알고리즘 수행
    - 이때 그림처럼 Swap out, swap in이 2번 일어나게됨 
    - 이때 **modify bit**를 사용해서 수정되었음을 나타내서 만약 쫓아낼 victim가 변경이 없다면 swap out과정을 생략하고 새로운 페이지를 올려놓는 swap in만 해도 됨 (table에 valid 값만 변경)
- update
- 재수행



### Algorithm

```
reference string
: 알고리즘을 효과적으로 표현하기 위한 방법 
ex) [가장 이전 접근] 1,2,3,4,1,2,5,1,2,3,4,5 [가장 최근 접근]
```

### **Optimal Algorithm**

```
MIN(OPT) : 가장 먼 미래에 참조되는 page를 replace 
```

- 비현실적임 
- offline algorithm 이라고 부름
  - 실제로 실시간으로 사용되진 않고 다른 알고리즘을 만들었을 때 얼마나 성능이 좋은지 나타내는 가이드라인정도로 사용 (upper bound) 
- **1,2,3,4,**1,2,**5,**1,2,3,**4,**5 [6 faults]



### **FIFO**

```
먼저 들어온 것을 먼저 내쫓음
```

- 이 때 frame크기가 커져도 오히려 page fault가 증가하는 Belady's Anomlay가 발생하기도 함
  - 3 frame의 경우 fault 9번
    - **1,2,3,4,1,2,5,**1,2**,3,4,5**
  - 4 frame의 경우 fault 10번
    - **1,2,3,4,**1,2,**5,1,2,3,4,5**



### **LRU (Least Recently Used)** <가장 많이 쓰임>

```java
가장 오래 전에 참조된 것을 지움 
```

- **1,2,3,4**,1,2,**5,**1,2,**3,4,5** [8 faults] 
- 성능이 좋음

- 구현시 '시간' 개념이 있어야함 

  

**Counter based 카운터 기반**

- LFU(Least Frequently Used) 
  - 참조 횟수(reference count)가 가장 적은 페이지를 지움 
  - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 *인기도*를 좀 더 정확히 *반영*할 수 있음 
  - 참조 시점의 최근성을 반영하지 못함 
  - LRU보다 구현이 복잡
    - 참조횟수 minHeap으로 O(Log N)에 구현 
- MFU (Most Frequently Used)



**LRU 구현 방법**

1. Counter implementation
   1. 각 페이지마다 시간정보 counter를 기록
   2. counter 값이 가장 작은게 LRU
   3. O(N) 매번 시간 비교 필요 
2. **Doubly LinkedList** 사용. head가 LRU고 tail이 MRU라면
   1. **저장된 데이터들의 순서를 유지** , 매번 tail을 update
   2. 가장 이전에 접근되었던 page는 head가 가리키고 있을 것 
   3. Java의 LinkedHashMap
   4. **O(1) 시간복잡도** (쫓아내기 위해서 비교가 필요하지 않음)
   5. ![스크린샷 2022-03-28 오전 2.28.15](./img/스크린샷%202022-03-28%20오전%202.28.15.png)





### **다양한 캐싱 환경**

- 캐싱 기법
  - 한정된 빠른 공간(캐시)에 요청된 데이터를 저장해두었다가 후속 요청시 캐시로부터 직접 서비스하는 방식
  - paging sytem외에도 캐시 메모리, 버퍼 캐시, 웹 캐싱 등 다양한 분야에 사용됨
- 캐시 운영의 시간 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없음
  - 버퍼 캐싱, 웹 캐싱
    - O(1) , O(Log N)정도까지 허용
  - 페이징 시스템 *-- 실제로 LRU 사용을 할 수 없음* 
    - page fault인경우에만 OS가 관여 
    - 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없음
    - O(1)인 LRU의 list조작 조차 불가능 



### LRU 근사 알고리즘 - 실제로 사용 

**Clock Algorithm** (= second chance algorithm)

![스크린샷 2022-03-28 오전 2.40.52](./img/스크린샷%202022-03-28%20오전%202.40.52.png)  

reference bit(access bit)를 활용해서 체크

- bit 1 : 최근에 사용되었음
- bit 0 : 최근에 사용되지 않았음 

```bash
아이디어:
clock방향으로 움직이며 지나가는 프레임의 레퍼런스 비트가 1인 경우 0으로 바꾸면서 읽고, 가장 처음 만나는 0을 victim으로 선정 

즉, 페이지가 사용될 때 "하드웨어가" 페이지에 대한 "reference bit를 1로 체크"하고, 페이지 교체가 필요해지면 "OS가" 비트를 1인경우 0으로 바꾸면서 읽다가 "처음 발견한 0비트 페이지를 victim으로 쫓아냄"

1인 비트는 한번 더 기회를 준다고 해서 second chance 알고리즘이라고도 한다. 
```



**Enhanced Second Chance Algorithm 비트2개 사용 **

```
reference bit, modify bit 2개 사용
- reference bit : 최근에 참조된 페이지 
- modify bit: 최근에 변경된 페이지 (I/O를 동반하는 페이지)
```

페이지가 메모리에 올라온 이후로 수정이 됐으면, 쫓겨날 때 그냥 쫓아내는게 아니고 디스크에 swap out으로 덮어써준 후 쫓아내야하고, 수정이 되지 않았으면 그냥 쫓아내기만 하면 된다. 



### Page Frame의 Allocation(할당)

```
Allocation Problem:
각 프로세스에 얼마만큼의 페이지 프레임을 할당할 것인가?
```

- 할당의 필요성
  - 메모리 참조 명령어 수행시 명령어, 데이터 등 여러 페이지를 동시에 참조
    - 명령어 수행을 위해 최소한 할당되어야 하는 프레임 수가 있음
  - Loop를 구성하는 페이지들은 한꺼번에 할당되는 것이 유리함
    - 최소한의 할당이 없으면 Loop마다 매번 page fault
- Allocation Scheme
  - Equal allocation : 모든 프로세스에 똑같은 갯수 할당
  - Proportional allocation : 프로세스 크기에 비례하여 할당
  - Priority allocation : 프로세스의 priority에 따라 다르게 할당 



**Global Replacement**

- Replace시 다른 프로세스에 할당된 프레임을 빼앗아올 수 있다.
- 프로세스별 할당량을 조절하는 또다른 방법
- working set, PFF 알고리즘 사용 

- 특정 프로그램이 메모리 독식할 수 있음 

**Local Replacement** (미리 할당 후 그 안에서 경쟁)

- 자신에게 할당된 프레임 내에서만 replacement



## Thrasing (쓰레싱 )

```
메모리가 부족해서 발생되는 현상
메모리에 올라와있는 프로세스 수가 증가함에따라, 오히려 CPU 이용률이 감소하는 현상
```

![스크린샷 2022-03-28 오전 2.57.16](./img/스크린샷 2022-03-28 오전 2.57.16.png)

- 원인
  - 메모리 부족으로 swap in/out으로 시간을 많이 쓰게됨 
  - 교체가 많이 발생해서 page fault로 swap in/out이 많이 일어나서 disk접근시간이 많아져 cpu utilization이 낮아짐
- 결과
  - CPU Utilization 낮아짐 
  - OS는 Multiprogramming degree를 높이려고 다른 프로세스 추가
  - 프로세스당 할당된 frame수 감소
  - swap in/out으로 CPU는 기다리기만 할 것 
  - low throughput



### **쓰레싱 예방 방법 :  Working-set Model**

```bash
"Locality of reference" "참조 지역성"
프로세스는 특정 시간동안 일정 장소만을 집중적으로 참조한다.
집중적으로 참조되는 해당 페이지들의 집합을 locality set이라고 함 
```

- Locality에 기반하여 프로세스가 일정 시간동안 원할하게 수행되기 위해 한꺼번에 메모리에 올라와있어야 하는 page들의 집합을 `Working Set`이라 정의

- Working Set 모델에서는 전체가 메모리에 올라오거나, 그렇지 않을 경우 모두 반납 (하나라도 확실하게 보장)

- 쓰레싱을 방지함

- Multiprogramming degree를 결정함

  

**Working-Set Algorithm**

- window size, working set으로 계산 
- 과거 size만큼 사용된 페이지가 working set으로 두고 거기 속한 페이지만 메모리에 유지, 속하지 않은 것은 버림 

![스크린샷 2022-03-28 오전 3.06.39](./img/스크린샷%202022-03-28%20오전%203.06.39.png)  

- 쓰레싱 방지
  - Working Set의 Size와 현재 가능한 메모리 프레임 개수(M)를 비교해서 
    - WSS > M 이면 스레싱이 발생했으므로 모두 빼앗음
    - WSS <= M 이면 메모리 제공   



**Page Size 결정**

- 페이지 사이즈를 감소시키면
  - 페이지 수 증가, 페이지 테이블 크기 증가
  - 내부 단편화 감소
  - Disk transfer의 효율성 감소 , Locality 활용 측면에서는 좋지 않음
  - 필요한 정보만 올라오므로 메모리 이용 효율성 증가
- 기본 : 4KB, 점점 크게 사용하는 추세



## 커널 메모리 할당 Allocation Kernel Memory

```
커널에도 메모리 할당이 필요할 때가 있음
ex) 프로세스가 생성됐을 때 PCB크기만큼 할당, 세마포 생성 등 

- user memory와 별도의 함수로 처리
- 별도의 free memory pool에서 할당

요지
- 다양한 크기의 자료구조를 사용하므로 낭비 최소화 (page 내부 단편화 줄이기위함)
- 연속적 메모리 할당이 필요한 경우가 있음 
```

- Buddy System
- Slab Allocator



### Slab Allocation 슬랩 할당

```
목적
1. 내부 단편화 줄이기 (낭비되는 공간 최소화)
2. 빠르게 메모리를 할당하기 

예시 - 세마포 캐시
세마포 사이즈가 7KB라면 생성할 때 마다 페이지 2개 할당(8KB) -> 매번 1KB씩 낭비된다.
1KB씩 낭비되는 내부 단편화를 줄이고, 매번 호출시마다 별도 할당하는 오버헤드를 줄여보자는 목적 
```

- **Slab ** : 하나 또는 그 이상의 페이지로 구성된 연속된 페이지 공간을 미리 할당 
- **cache** : 하나 이상의 Slab으로 구성되어 동일 타입의 커널 object의 집합소 

![img](https://t1.daumcdn.net/cfile/tistory/261F593655A739230F)  

**Slab : 먼저 연속적인 메모리 공간 할당**

![스크린샷 2022-03-28 오전 3.47.58](./img/스크린샷%202022-03-28%20오전%203.47.58.png)  

미리 할당했다가 이미 할당된 공간에서 주소만 가져다쓴다.

- 장점
  - 내부 단편화 발생 X
  - 매번 메모리할당 별도로 할 필요 없어 빨라짐
- 객체 상태(캐시)
  - free  맨 처음 할당됐을때
  - used 캐시에서 할당된 객체 `kmem_cache_alloc`
- 슬랩 상태
  - Full / Empty / Partial 
- 슬랩 할당
  - Partial 슬랩의 객체로 할당 -> Empty 슬랩으로부터 할당 -> 연속된 새로운 Slab만들어 할당 



### Buddy System 버디 시스템

```
물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로 부터 메모리 할당
```

- 메모리는 2^n 단위로 할당 
  - 6개 페이지 요청 -> 8개 할당
  - 50개 요청 -> 64개 할당
- 가능한 큰 메모리공간(Buddy) 이용해 관리
  - 인접 메모리를 하나로 묶어 관리
- Splitting, Coalescing현상 발생 

![스크린샷 2022-03-28 오전 3.45.37](./img/스크린샷%202022-03-28%20오전%203.45.37.png)



---



- 출처
  - 공룡책
  - 이화여대 반효경교수님 운영체제 강의
  - 내 학교수업 강의필기노트